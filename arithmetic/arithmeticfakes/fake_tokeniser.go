// Code generated by counterfeiter. DO NOT EDIT.
package arithmeticfakes

import (
	"sync"

	"github.com/kieron-dev/lsbasi/arithmetic"
	"github.com/kieron-dev/lsbasi/lexer"
)

type FakeTokeniser struct {
	CurrentTokenStub        func() lexer.Token
	currentTokenMutex       sync.RWMutex
	currentTokenArgsForCall []struct {
	}
	currentTokenReturns struct {
		result1 lexer.Token
	}
	currentTokenReturnsOnCall map[int]struct {
		result1 lexer.Token
	}
	EatStub        func(lexer.TokenType) error
	eatMutex       sync.RWMutex
	eatArgsForCall []struct {
		arg1 lexer.TokenType
	}
	eatReturns struct {
		result1 error
	}
	eatReturnsOnCall map[int]struct {
		result1 error
	}
	NextTokenStub        func() (lexer.Token, error)
	nextTokenMutex       sync.RWMutex
	nextTokenArgsForCall []struct {
	}
	nextTokenReturns struct {
		result1 lexer.Token
		result2 error
	}
	nextTokenReturnsOnCall map[int]struct {
		result1 lexer.Token
		result2 error
	}
	invocations      map[string][][]interface{}
	invocationsMutex sync.RWMutex
}

func (fake *FakeTokeniser) CurrentToken() lexer.Token {
	fake.currentTokenMutex.Lock()
	ret, specificReturn := fake.currentTokenReturnsOnCall[len(fake.currentTokenArgsForCall)]
	fake.currentTokenArgsForCall = append(fake.currentTokenArgsForCall, struct {
	}{})
	stub := fake.CurrentTokenStub
	fakeReturns := fake.currentTokenReturns
	fake.recordInvocation("CurrentToken", []interface{}{})
	fake.currentTokenMutex.Unlock()
	if stub != nil {
		return stub()
	}
	if specificReturn {
		return ret.result1
	}
	return fakeReturns.result1
}

func (fake *FakeTokeniser) CurrentTokenCallCount() int {
	fake.currentTokenMutex.RLock()
	defer fake.currentTokenMutex.RUnlock()
	return len(fake.currentTokenArgsForCall)
}

func (fake *FakeTokeniser) CurrentTokenCalls(stub func() lexer.Token) {
	fake.currentTokenMutex.Lock()
	defer fake.currentTokenMutex.Unlock()
	fake.CurrentTokenStub = stub
}

func (fake *FakeTokeniser) CurrentTokenReturns(result1 lexer.Token) {
	fake.currentTokenMutex.Lock()
	defer fake.currentTokenMutex.Unlock()
	fake.CurrentTokenStub = nil
	fake.currentTokenReturns = struct {
		result1 lexer.Token
	}{result1}
}

func (fake *FakeTokeniser) CurrentTokenReturnsOnCall(i int, result1 lexer.Token) {
	fake.currentTokenMutex.Lock()
	defer fake.currentTokenMutex.Unlock()
	fake.CurrentTokenStub = nil
	if fake.currentTokenReturnsOnCall == nil {
		fake.currentTokenReturnsOnCall = make(map[int]struct {
			result1 lexer.Token
		})
	}
	fake.currentTokenReturnsOnCall[i] = struct {
		result1 lexer.Token
	}{result1}
}

func (fake *FakeTokeniser) Eat(arg1 lexer.TokenType) error {
	fake.eatMutex.Lock()
	ret, specificReturn := fake.eatReturnsOnCall[len(fake.eatArgsForCall)]
	fake.eatArgsForCall = append(fake.eatArgsForCall, struct {
		arg1 lexer.TokenType
	}{arg1})
	stub := fake.EatStub
	fakeReturns := fake.eatReturns
	fake.recordInvocation("Eat", []interface{}{arg1})
	fake.eatMutex.Unlock()
	if stub != nil {
		return stub(arg1)
	}
	if specificReturn {
		return ret.result1
	}
	return fakeReturns.result1
}

func (fake *FakeTokeniser) EatCallCount() int {
	fake.eatMutex.RLock()
	defer fake.eatMutex.RUnlock()
	return len(fake.eatArgsForCall)
}

func (fake *FakeTokeniser) EatCalls(stub func(lexer.TokenType) error) {
	fake.eatMutex.Lock()
	defer fake.eatMutex.Unlock()
	fake.EatStub = stub
}

func (fake *FakeTokeniser) EatArgsForCall(i int) lexer.TokenType {
	fake.eatMutex.RLock()
	defer fake.eatMutex.RUnlock()
	argsForCall := fake.eatArgsForCall[i]
	return argsForCall.arg1
}

func (fake *FakeTokeniser) EatReturns(result1 error) {
	fake.eatMutex.Lock()
	defer fake.eatMutex.Unlock()
	fake.EatStub = nil
	fake.eatReturns = struct {
		result1 error
	}{result1}
}

func (fake *FakeTokeniser) EatReturnsOnCall(i int, result1 error) {
	fake.eatMutex.Lock()
	defer fake.eatMutex.Unlock()
	fake.EatStub = nil
	if fake.eatReturnsOnCall == nil {
		fake.eatReturnsOnCall = make(map[int]struct {
			result1 error
		})
	}
	fake.eatReturnsOnCall[i] = struct {
		result1 error
	}{result1}
}

func (fake *FakeTokeniser) NextToken() (lexer.Token, error) {
	fake.nextTokenMutex.Lock()
	ret, specificReturn := fake.nextTokenReturnsOnCall[len(fake.nextTokenArgsForCall)]
	fake.nextTokenArgsForCall = append(fake.nextTokenArgsForCall, struct {
	}{})
	stub := fake.NextTokenStub
	fakeReturns := fake.nextTokenReturns
	fake.recordInvocation("NextToken", []interface{}{})
	fake.nextTokenMutex.Unlock()
	if stub != nil {
		return stub()
	}
	if specificReturn {
		return ret.result1, ret.result2
	}
	return fakeReturns.result1, fakeReturns.result2
}

func (fake *FakeTokeniser) NextTokenCallCount() int {
	fake.nextTokenMutex.RLock()
	defer fake.nextTokenMutex.RUnlock()
	return len(fake.nextTokenArgsForCall)
}

func (fake *FakeTokeniser) NextTokenCalls(stub func() (lexer.Token, error)) {
	fake.nextTokenMutex.Lock()
	defer fake.nextTokenMutex.Unlock()
	fake.NextTokenStub = stub
}

func (fake *FakeTokeniser) NextTokenReturns(result1 lexer.Token, result2 error) {
	fake.nextTokenMutex.Lock()
	defer fake.nextTokenMutex.Unlock()
	fake.NextTokenStub = nil
	fake.nextTokenReturns = struct {
		result1 lexer.Token
		result2 error
	}{result1, result2}
}

func (fake *FakeTokeniser) NextTokenReturnsOnCall(i int, result1 lexer.Token, result2 error) {
	fake.nextTokenMutex.Lock()
	defer fake.nextTokenMutex.Unlock()
	fake.NextTokenStub = nil
	if fake.nextTokenReturnsOnCall == nil {
		fake.nextTokenReturnsOnCall = make(map[int]struct {
			result1 lexer.Token
			result2 error
		})
	}
	fake.nextTokenReturnsOnCall[i] = struct {
		result1 lexer.Token
		result2 error
	}{result1, result2}
}

func (fake *FakeTokeniser) Invocations() map[string][][]interface{} {
	fake.invocationsMutex.RLock()
	defer fake.invocationsMutex.RUnlock()
	fake.currentTokenMutex.RLock()
	defer fake.currentTokenMutex.RUnlock()
	fake.eatMutex.RLock()
	defer fake.eatMutex.RUnlock()
	fake.nextTokenMutex.RLock()
	defer fake.nextTokenMutex.RUnlock()
	copiedInvocations := map[string][][]interface{}{}
	for key, value := range fake.invocations {
		copiedInvocations[key] = value
	}
	return copiedInvocations
}

func (fake *FakeTokeniser) recordInvocation(key string, args []interface{}) {
	fake.invocationsMutex.Lock()
	defer fake.invocationsMutex.Unlock()
	if fake.invocations == nil {
		fake.invocations = map[string][][]interface{}{}
	}
	if fake.invocations[key] == nil {
		fake.invocations[key] = [][]interface{}{}
	}
	fake.invocations[key] = append(fake.invocations[key], args)
}

var _ arithmetic.Tokeniser = new(FakeTokeniser)
